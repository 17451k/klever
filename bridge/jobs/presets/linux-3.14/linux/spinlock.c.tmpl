#include <linux/ldv/common.h>
#include <verifier/common.h>
#include <verifier/nondet.h>
#include <linux/spinlock_types.h>

// for arg_sign in spinlock_arg_signs
static int ldv_spin{{ arg_sign.id }} = 1;

/* MODEL_FUNC_DEF Check that spinlock{{ arg_sign.text }} was not locked and lock it */
void ldv_spin_lock{{ arg_sign.id }}(void)
{
	/* ASSERT Spinlock{{ arg_sign.text }} must be unlocked */
	ldv_assert("linux:spinlock::one thread:double lock", ldv_spin{{ arg_sign.id }} == 1);
	/* OTHER Cut all infeasible paths */
	ldv_assume(ldv_spin{{ arg_sign.id }} == 1);
	/* CHANGE_STATE Lock spinlock{{ arg_sign.text }} */
	ldv_spin{{ arg_sign.id }} = 2;
}

/* MODEL_FUNC_DEF Check that spinlock{{ arg_sign.text }} was locked and unlock it */
void ldv_spin_unlock{{ arg_sign.id }}(void)
{
	/* ASSERT Spinlock{{ arg_sign.text }} must be locked */
	ldv_assert("linux:spinlock::one thread:double unlock", ldv_spin{{ arg_sign.id }} == 2);
	/* OTHER Cut all infeasible paths */
	ldv_assume(ldv_spin{{ arg_sign.id }} == 2);
	/* CHANGE_STATE Unlock spinlock{{ arg_sign.text }} */
	ldv_spin{{ arg_sign.id }} = 1;
}

/* MODEL_FUNC_DEF Check that spinlock{{ arg_sign.text }} was not locked and nondeterministically lock it */
int ldv_spin_trylock{{ arg_sign.id }}(spinlock_t *lock)
{
	int is_spin_held_by_another_thread;

	/* ASSERT It may be bug if spinlock{{ arg_sign.text }} is locked at this point */
	ldv_assert("linux:spinlock::one thread:double lock try", ldv_spin{{ arg_sign.id }} == 1);
	/* OTHER Cut all infeasible paths */
	ldv_assume(ldv_spin{{ arg_sign.id }} == 1);

	/* OTHER Construct nondetermined result */
	is_spin_held_by_another_thread = ldv_undef_int();

	/* OTHER Nondeterministically lock spinlock{{ arg_sign.text }} */
	if (is_spin_held_by_another_thread) {
		/* RETURN Spinlock{{ arg_sign.text }} was not locked. Finish with fail */
		return 0;
	}
	else {
		/* CHANGE_STATE Lock spinlock{{ arg_sign.text }} */
		ldv_spin{{ arg_sign.id }} = 2;
		/* RETURN Finish with success */
		return 1;
	}
}

/* MODEL_FUNC_DEF The same thread can not both lock spinlock{{ arg_sign.text }} and wait until it will be unlocked */
void ldv_spin_unlock_wait{{ arg_sign.id }}(void)
{
	/* ASSERT Spinlock{{ arg_sign.text }} must not be locked by current thread */
	ldv_assert("linux:spinlock::one thread:double lock try", ldv_spin{{ arg_sign.id }} == 1);
	/* OTHER Cut all infeasible paths */
	ldv_assume(ldv_spin{{ arg_sign.id }} == 1);
}

/* MODEL_FUNC_DEF Check whether spinlock{{ arg_sign.text }} was locked */
int ldv_spin_is_locked{{ arg_sign.id }}(spinlock_t *lock)
{
	int is_spin_held_by_another_thread;

	/* OTHER Construct nondetermined result */
	is_spin_held_by_another_thread = ldv_undef_int();

	/* OTHER Nondeterministically understand whether spinlock{{ arg_sign.text }} was locked */
	if(ldv_spin{{ arg_sign.id }} == 1 && !is_spin_held_by_another_thread) {
		/* RETURN Spinlock{{ arg_sign.text }} is not locked */
		return 0;
	}
	else {
		/* RETURN Spinlock{{ arg_sign.text }} was locked */
		return 1;
	}
}

/* MODEL_FUNC_DEF Check whether spinlock{{ arg_sign.text }} was not locked */
int ldv_spin_can_lock{{ arg_sign.id }}(spinlock_t *lock)
{
	/* RETURN Inverse function for spin_is_locked() */
	return !ldv_spin_is_locked{{ arg_sign.id }}(lock);
}

/* MODEL_FUNC_DEF Check whether spinlock{{ arg_sign.text }} is contended */
int ldv_spin_is_contended{{ arg_sign.id }}(void)
{
	int is_spin_contended;

	/* OTHER Construct nondetermined result */
	is_spin_contended = ldv_undef_int();

	/* OTHER Nondeterministically understand whether spinlock{{ arg_sign.text }} is contended */
	if(is_spin_contended) {
		/* RETURN Spinlock{{ arg_sign.text }} is contended */
		return 0;
	}
	else {
		/* RETURN Spinlock{{ arg_sign.text }} is not contended */
		return 1;
	}
}

/* MODEL_FUNC_DEF Lock spinlock{{ arg_sign.text }} if atomic decrement result is zero */
int ldv_atomic_dec_and_lock{{ arg_sign.id }}(spinlock_t *lock)
{
	int atomic_value_after_dec;

	/* ASSERT Spinlock{{ arg_sign.text }} must be unlocked (since we may lock it in this function) */
	ldv_assert("linux:spinlock::one thread:double lock try", ldv_spin{{ arg_sign.id }} == 1);
	/* OTHER Cut all infeasible paths */
	ldv_assume(ldv_spin{{ arg_sign.id }} == 1);

	/* OTHER Assign result of atomic decrement */
	atomic_value_after_dec = ldv_undef_int();

	/* OTHER Atomic decrement result is zero */
	if (atomic_value_after_dec == 0) {
		/* CHANGE_STATE Lock spinlock{{ arg_sign.text }} */
		ldv_spin{{ arg_sign.id }} = 2;
		/* RETURN Finish with success */
		return 1;
	}

	/* RETURN Atomic decrement result is not zero. Finish with fail without locking spin{{ arg_sign.text }} */
	return 0;
}
// endfor

/* MODEL_FUNC_DEF Check that all spinlocks are unlocked at the end */
void ldv_check_final_state(void)
{
	// for arg_sign in spinlock_arg_signs
	/* ASSERT Spinlock{{ arg_sign.text }} must be unlocked before finishing operation */
	ldv_assert("linux:spinlock::one thread:locked at exit", ldv_spin{{ arg_sign.id }} == 1);
	// endfor
}

/* For 'linux:alloc:spin lock' rule */
int ldv_exclusive_spin_is_locked(void)
{
	// for arg_sign in spinlock_arg_signs
	/* OTHER Nondeterministically understand whether spinlock{{ arg_sign.text }} was locked */
	if(ldv_spin{{ arg_sign.id }} == 2) {
		/* RETURN Spinlock{{ arg_sign.text }} is locked */
		return 1;
	}
	// endfor
	/* RETURN None of the spinlocks are locked */
	return 0;
}
